{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "MD6Up0Lj0Lb4",
    "outputId": "4882a47f-0e99-4a7f-e838-6c5baa7cdba3"
   },
   "outputs": [],
   "source": [
    "## For colab runs\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# !cp -r /content/gdrive/My\\ Drive/uploads/rogozin .\n",
    "# !cp rogozin/decentralized_methods-develop.zip .\n",
    "# !unzip -qn decentralized_methods-develop.zip\n",
    "# !mv decentralized_methods-develop/* .\n",
    "# !rm decentralized_methods-develop* -rf\n",
    "\n",
    "# !unzip -qn rogozin/vladiku.zip -d data\n",
    "# !bunzip2 data/*.bz2\n",
    "\n",
    "# !sed -ri '8d' src/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ORqFnwUjzZOx"
   },
   "source": [
    "# DGM Minimal Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9jcDHlTtzZOy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from pathlib import Path\n",
    "\n",
    "from src.objectives import ( \n",
    "    Objective,\n",
    "    LeastSquares, LogRegression,\n",
    "    StochLeastSquares, StochLogRegression)\n",
    "from src.methods import (\n",
    "    EXTRA, DIGing, DSGD,\n",
    "    DAccGD, Mudag, APM1_C,\n",
    "    SDAccGD, SMudag, SAPM1_C)\n",
    "from src.utils import PythonGraph, expected_lambda2\n",
    "\n",
    "# from src.sparse import objectives as obj\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tkh45M9rzZPG"
   },
   "outputs": [],
   "source": [
    "TASK = LeastSquares\n",
    "# TASK = LogRegression \n",
    "\n",
    "DDIR = 'logreg_solutions' if TASK == LogRegression else 'least_squares_solutions' \n",
    "DSDIR = Path('data/YearPredictionMSD')\n",
    "DDIR = Path(DDIR)\n",
    "\n",
    "num_nodes = 20\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "soldir =  DDIR / DSDIR.name\n",
    "\n",
    "A, b = load_svmlight_file(str(DSDIR))\n",
    "A = torch.Tensor(A.todense()).to(device)\n",
    "b = torch.Tensor(b).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = list(soldir.iterdir())[0].name\n",
    "sigma = float(fname.split('=')[1])\n",
    "\n",
    "with open(soldir/fname, 'rb') as file:\n",
    "    f_star = pickle.load(file)['func_star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVD5IJ0HzZPP"
   },
   "outputs": [],
   "source": [
    "# For simulating a graph evolution,\n",
    "# only graphs like 'erdos_renyi' is appropriate\n",
    "\n",
    "p = .68\n",
    "graph = 'random_geometric'\n",
    "# graph = 'erdos_renyi'\n",
    "# graph = 'path'\n",
    "# graph = 'cycle'\n",
    "# graph = 'complete'\n",
    "\n",
    "F = TASK(A, b, num_nodes, sigma)\n",
    "X0 = torch.zeros(num_nodes, A.size(1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = torch.svd(A)[1][0] ** 2 / (4*len(A))\n",
    "kappa_g = torch.svd(F.A)[1][:, 0].mean() / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVD5IJ0HzZPP"
   },
   "outputs": [],
   "source": [
    "gen = lambda : PythonGraph(F, graph, p).gen()[1]\n",
    "E_s2,_ = expected_lambda2(gen, 5000)\n",
    "\n",
    "####\n",
    "# Fixing seed doesn't really make a difference\n",
    "####\n",
    "# torch.manual_seed(123)  #  I don't remember whether I use torch random numbers anywhere\n",
    "# random.seed(123)  #  networkx depends on lib random\n",
    "# graphs = [PythonGraph(F, graph, p).gen()[1] for _ in range(int(1e4))]\n",
    "\n",
    "# class GraphEvolution:\n",
    "#     def __init__(self, graphs):\n",
    "#         self.gi = iter(graphs)\n",
    "        \n",
    "#     def __call__(self):\n",
    "#         return next(self.gi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVD5IJ0HzZPP"
   },
   "outputs": [],
   "source": [
    "opts = []\n",
    "opts.append(\n",
    "    EXTRA(F, gen, eta=.01/F.b.norm()))\n",
    "\n",
    "opts.append(\n",
    "    DIGing(F, gen, eta=.01/F.b.norm()))\n",
    "\n",
    "consensus_iters = 3\n",
    "opts.append(\n",
    "    DAccGD(F, gen, L=L, mu=sigma, con_iters=consensus_iters))\n",
    "\n",
    "consensus_iters = 5\n",
    "opts.append(\n",
    "    SDAccGD(F, gen, L=L, mu=sigma, E_s2=E_s2, con_iters=consensus_iters))\n",
    "\n",
    "consensus_iters = 2\n",
    "opts.append(\n",
    "    SMudag(F, gen, L=L, mu=sigma, E_s2=E_s2, con_iters=consensus_iters))\n",
    "\n",
    "opts.append(\n",
    "    SAPM1_C(F, gen, L=L, mu=sigma, E_s2=E_s2, beta=0, scale=100))  # NOTE: tune up scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVD5IJ0HzZPP"
   },
   "outputs": [],
   "source": [
    "# opts = []\n",
    "# W = gen()\n",
    "# opts.append(\n",
    "#     Mudag(F, W, L=L, mu=sigma, M=L, kappa_g=kappa_g, scale=1.))\n",
    "# \n",
    "# beta = 0\n",
    "# opts.append(\n",
    "#     APM1_C(F, W, L=L, mu=sigma, beta=beta, scale=100))  # NOTE: tune up scale\n",
    "# \n",
    "# M has almost no effect on the convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_iters = 1000\n",
    "\n",
    "for opt in opts:\n",
    "    opt.run(X0, n_iters=n_iters);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-NO2bdazZPX"
   },
   "outputs": [],
   "source": [
    "XAXIS = 'nmix'\n",
    "# XAXIS = 'i'\n",
    "XLIM = n_iters if XAXIS == 'i' else min([opt.logs['nmix'][-1] for opt in opts]) / 1.2\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i, opt in enumerate(opts):\n",
    "    lbl = opt.__class__.__name__\n",
    "    span = np.searchsorted(opt.logs[XAXIS], XLIM)\n",
    "    plt.plot(\n",
    "        opt.logs[XAXIS][:span], opt.logs['fn'][:span] - f_star,\n",
    "        marker=i+5, label=lbl, markevery=n_iters//(5+i*3))  # FIXME: change abs marker frequency to relative\n",
    "    \n",
    "plt.title('Optimization Functional Value over Iteration Number', size=20)\n",
    "plt.ylabel(r'$f(\\overline{x}_k) - f^*$', size=20)\n",
    "plt.xlabel('communication steps', size=20)\n",
    "# plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.legend();\n",
    "\n",
    "# plt.savefig('../Decentralized + inexactness/en/figures/a9a_residual.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WUEDQVuczZPd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "XAXIS = 'nmix'\n",
    "# XAXIS = 'i'\n",
    "XLIM = n_iters if XAXIS == 'i' else min([opt.logs['nmix'][-1] for opt in opts])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i, opt in enumerate(opts):\n",
    "    lbl = opt.__class__.__name__\n",
    "    span = np.searchsorted(opt.logs[XAXIS], XLIM)\n",
    "    plt.plot(\n",
    "        opt.logs['nmix'][:span], opt.logs['dist2con'][:span],\n",
    "        marker=i+5, label=lbl, markevery=n_iters//(5+i*3))  # FIXME: change abs marker frequency to relative\n",
    "\n",
    "plt.ylabel(r'$||(I-\\frac{1}{n}11^T)X||^2$', size=20)\n",
    "plt.xlabel('communication steps', size=20)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid();\n",
    "\n",
    "# plt.savefig('../Decentralized + inexactness/en/figures/a9a_consensus.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IaH8GF1aBsmc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Initialization Cell",
  "colab": {
   "collapsed_sections": [],
   "name": "experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
