{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9jcDHlTtzZOy"
   },
   "outputs": [],
   "source": [
    "## Python libs\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "MD6Up0Lj0Lb4",
    "outputId": "4882a47f-0e99-4a7f-e838-6c5baa7cdba3"
   },
   "outputs": [],
   "source": [
    "COLAB = False\n",
    "\n",
    "## There must be data 'vladiku.zip' and zip of repository\n",
    "## https://github.com/alexrogozin12/decentralized_methods (private at the date of coding)\n",
    "## in google-drive folder 'GDDIR'\n",
    "GDDIR = 'uploads/rogozin'\n",
    "\n",
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    !cp -r /content/gdrive/My\\ Drive/{GDDIR} .\n",
    "    !unzip -qn {Path(GDDIR).name}/vladiku.zip -d data\n",
    "    !bunzip2 data/*.bz2\n",
    "\n",
    "    !git clone https://github.com/alexrogozin12/decentralized_methods.git\n",
    "    !mv decentralized_methods/* .\n",
    "    !rm decentralized_methods -rf\n",
    "    !sed -ri '8d' src/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "ORqFnwUjzZOx",
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# DGM Minimal Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9jcDHlTtzZOy"
   },
   "outputs": [],
   "source": [
    "## Local libs\n",
    "\n",
    "from src.objectives import ( \n",
    "    LeastSquares, LogRegression,\n",
    "    StochLeastSquares, StochLogRegression)\n",
    "from src.methods import (\n",
    "    EXTRA, DIGing, DSGD,\n",
    "    DAccGD, Mudag, APM_C,\n",
    "    SDAccGD, SMudag, SAPM_C)\n",
    "from src.utils import PythonGraph, expected_lambda2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tkh45M9rzZPG"
   },
   "outputs": [],
   "source": [
    "TASK = LeastSquares\n",
    "# TASK = LogRegression \n",
    "\n",
    "DDIR = 'logreg_solutions' if TASK == LogRegression else 'least_squares_solutions' \n",
    "DSDIR = Path('data/cadata_scaled')\n",
    "DDIR = Path(DDIR)\n",
    "\n",
    "num_nodes = 20\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "soldir = DDIR / DSDIR.name\n",
    "\n",
    "A, b = load_svmlight_file(str(DSDIR))\n",
    "\n",
    "A_cpu = torch.Tensor(A.todense())\n",
    "b_cpu = torch.Tensor(b)\n",
    "\n",
    "A = A_cpu.to(device)\n",
    "b = b_cpu.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = list(soldir.iterdir())[0].name\n",
    "sigma = float(fname.split('=')[1])\n",
    "\n",
    "with open(soldir/fname, 'rb') as file:\n",
    "    f_star = pickle.load(file)['func_star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVD5IJ0HzZPP"
   },
   "outputs": [],
   "source": [
    "# For simulating a graph evolution,\n",
    "# only graphs like 'erdos_renyi' and 'random_geometric' are appropriate\n",
    "\n",
    "p = .68\n",
    "graph = 'random_geometric'\n",
    "# graph = 'erdos_renyi'\n",
    "# graph = 'path'\n",
    "# graph = 'cycle'\n",
    "# graph = 'complete'\n",
    "\n",
    "F = TASK(A, b, num_nodes, sigma)\n",
    "F_cpu = TASK(A_cpu, b_cpu, num_nodes, sigma)\n",
    "X0 = torch.zeros(num_nodes, A.size(1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = torch.svd(A)[1][0] ** 2 / (4*len(A))\n",
    "kappa_g = torch.svd(F.A)[1][:, 0].mean() / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVD5IJ0HzZPP"
   },
   "outputs": [],
   "source": [
    "gen = lambda : PythonGraph(F, graph, p).gen()[1]\n",
    "_gen = lambda: PythonGraph(F_cpu, graph, p).gen()[1]\n",
    "E_s2,_ = expected_lambda2(_gen, 5000)\n",
    "\n",
    "####\n",
    "# Fixing seed doesn't really make a difference\n",
    "####\n",
    "# torch.manual_seed(123)  #  I don't remember whether I use torch random numbers anywhere\n",
    "# random.seed(123)  #  networkx depends on lib random\n",
    "# graphs = [PythonGraph(F, graph, p).gen()[1] for _ in range(int(1e4))]\n",
    "\n",
    "# class GraphEvolution:\n",
    "#     def __init__(self, graphs):\n",
    "#         self.gi = iter(graphs)\n",
    "        \n",
    "#     def __call__(self):\n",
    "#         return next(self.gi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVD5IJ0HzZPP"
   },
   "outputs": [],
   "source": [
    "opts = []\n",
    "opts.append(\n",
    "    EXTRA(F, gen, eta=.01/F.b.norm()))\n",
    "\n",
    "opts.append(\n",
    "    DIGing(F, gen, eta=.01/F.b.norm()))\n",
    "\n",
    "consensus_iters = 5\n",
    "opts.append(\n",
    "    DAccGD(F, gen, L=L, mu=sigma, con_iters=consensus_iters))\n",
    "\n",
    "# consensus_iters = 5\n",
    "# opts.append(\n",
    "#     SDAccGD(F, gen, L=L, mu=sigma, E_s2=E_s2, con_iters=consensus_iters))\n",
    "\n",
    "consensus_iters = 20\n",
    "opts.append(\n",
    "    SMudag(F, gen, L=L, mu=sigma, E_s2=E_s2, con_iters=consensus_iters))\n",
    "\n",
    "opts.append(\n",
    "    SAPM_C(F, gen, L=L, mu=sigma, E_s2=E_s2, beta=0, scale=20000))  # NOTE: tune up 'scale'\n",
    "\n",
    "checkpoints = [[X0] for _ in range(len(opts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pay attention to the values of (EXTRA/DIGing).eta, SAPM_C._gamma (gamma depends on 'scale')\n",
    "print('EXTRA/DIGing eta', opts[0].eta.item())\n",
    "print('APM-C gamma', opts[-1]._gamma.item())\n",
    "assert opts[-1]._gamma <= 1, 'Too long to wait'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVD5IJ0HzZPP"
   },
   "outputs": [],
   "source": [
    "## Fixed mixing matrix algorithms\n",
    "## EXTRA and DIGing with a small correction in the code can be also regarded as such\n",
    "\n",
    "# opts = []\n",
    "# W = gen()\n",
    "# opts.append(\n",
    "#     Mudag(F, W, L=L, mu=sigma, M=L, kappa_g=kappa_g, scale=1.))  # NOTE: tune up 'scale'\n",
    "# \n",
    "# beta = 0\n",
    "# opts.append(\n",
    "#     APM_C(F, W, L=L, mu=sigma, beta=beta, scale=100))  # NOTE: tune up 'scale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Running the cell X times yields X * n_iters optimization steps of each optimizer\n",
    "## (if n_iters is not redefined during it). To run from scratch,\n",
    "## execute the cell with optimizers' initialization first\n",
    "\n",
    "n_iters = 500\n",
    "\n",
    "for i, opt in enumerate(opts):\n",
    "    X0, *args = checkpoints[i]\n",
    "    checkpoints[i] = opt.run(X0, *args, n_iters=n_iters);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_corrector(names):\n",
    "    corrected_names = []\n",
    "    for name in names:\n",
    "        if name[0] == 'S': new_name = name[1:]\n",
    "        else: new_name = name\n",
    "            \n",
    "        if new_name in names: new_name = name \n",
    "        new_name = new_name.replace('_', '-')\n",
    "        \n",
    "        corrected_names.append(new_name)\n",
    "    return corrected_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-NO2bdazZPX"
   },
   "outputs": [],
   "source": [
    "XAXIS = 'nmix'\n",
    "# XAXIS = 'i'\n",
    "XLIM = n_iters if XAXIS == 'i' else min([opt.logs['nmix'][-1] for opt in opts])\n",
    "XLBL = 'gradient steps' if XAXIS == 'i' else 'communication steps'\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "lbls = [opt.__class__.__name__ for opt in opts]\n",
    "lbls = name_corrector(lbls)\n",
    "\n",
    "for i, opt in enumerate(opts):\n",
    "    span = np.searchsorted(opt.logs[XAXIS], XLIM, 'right')\n",
    "    plt.plot(\n",
    "        opt.logs[XAXIS][:span], opt.logs['fn'][:span] - f_star,\n",
    "        marker=i+5, label=lbls[i], markevery=span//(4+math.ceil(i*1.8))+1)\n",
    "    \n",
    "plt.ylabel(r'$f(\\overline{x}_k) - f^*$', size=20)\n",
    "plt.xlabel(XLBL, size=20)\n",
    "\n",
    "#plt.ylim(0, 1.2*opts[0].logs['fn'][0])\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.legend();\n",
    "\n",
    "if COLAB:\n",
    "    plt.savefig(f'{DSDIR.name}-res_x{XAXIS}.png')\n",
    "    !mv {DSDIR.name}-res_x{XAXIS}.png /content/gdrive/My\\ Drive/{GDDIR}/figures\n",
    "else:\n",
    "    !mkdir -p figures\n",
    "    plt.savefig(f'figures/{DSDIR.name}-res_x{XAXIS}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WUEDQVuczZPd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "XAXIS = 'nmix'\n",
    "# XAXIS = 'i'\n",
    "XLIM = n_iters if XAXIS == 'i' else min([opt.logs['nmix'][-1] for opt in opts])\n",
    "XLBL = 'gradient steps' if XAXIS == 'i' else 'communication steps'\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "lbls = [opt.__class__.__name__ for opt in opts]\n",
    "lbls = name_corrector(lbls)\n",
    "\n",
    "for i, opt in enumerate(opts):\n",
    "    span = np.searchsorted(opt.logs[XAXIS], XLIM, 'right')\n",
    "    plt.plot(\n",
    "        opt.logs[XAXIS][:span], opt.logs['dist2con'][:span],\n",
    "        marker=i+5, label=lbls[i], markevery=span//(3+math.ceil(i*1.7))+1)\n",
    "\n",
    "plt.ylabel(r'$||(I-\\frac{1}{n}11^T)X||^2$', size=20)\n",
    "plt.xlabel(XLBL, size=20)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid();\n",
    "\n",
    "if COLAB:\n",
    "    plt.savefig(f'{DSDIR.name}-con_x{XAXIS}.png')\n",
    "    !mv {DSDIR.name}-con_x{XAXIS}.png /content/gdrive/My\\ Drive/{GDDIR}/figures\n",
    "else:\n",
    "    !mkdir -p figures\n",
    "    plt.savefig(f'figures/{DSDIR.name}-con_x{XAXIS}.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Initialization Cell",
  "colab": {
   "collapsed_sections": [],
   "name": "experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
