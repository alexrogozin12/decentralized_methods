{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGM Minimal Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from torch import autograd\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_decompose(N, m, b=8):\n",
    "    \"\"\"\n",
    "    Decomposes N into m terms: a_i, i=1,m;\n",
    "    so that: max_i a_i - min_i a_i <= 1 applies\n",
    "    --------\n",
    "    b is a number of bits used for an integer\n",
    "    in the output array\n",
    "    \"\"\"\n",
    "    terms = np.empty(m, dtype=f'i{b}')\n",
    "    terms[:] = math.floor(N/m)\n",
    "    terms[:N-terms.sum()] += 1\n",
    "    return terms.tolist() \n",
    "\n",
    "\n",
    "def D(y, x):\n",
    "    \"\"\"\n",
    "    Differential operator\n",
    "    \"\"\"\n",
    "    grad = autograd.grad(\n",
    "        outputs=y, inputs=x,\n",
    "        grad_outputs=torch.ones_like(y),\n",
    "        create_graph=True, allow_unused=True)\n",
    "\n",
    "    if len(grad) == 1:\n",
    "        return grad[0]\n",
    "    return grad\n",
    "\n",
    "\n",
    "def metropolis_weights(A):\n",
    "    A = A / (1 + torch.max(A.sum(1,keepdims=True),A.sum(0,keepdims=True)))\n",
    "    A.as_strided([len(A)], [len(A)+1]).copy_(1-A.sum(1))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective:\n",
    "    \"\"\"\n",
    "    Base class for optimization functional\n",
    "    \"\"\"\n",
    "    def __init__(self, A, b, num_nodes):\n",
    "        chunk_sizes = uniform_decompose(A.size(0), num_nodes)\n",
    "        self.A = pad_sequence(A.split(chunk_sizes), batch_first=True)\n",
    "        self.b = pad_sequence(b.split(chunk_sizes), batch_first=True)\n",
    "\n",
    "        \n",
    "class LeastSquares(Objective):\n",
    "    def __call__(self, X):\n",
    "        s = '' if X.ndim < 2 else 'i'\n",
    "        Y = torch.einsum(f'ijk,k{s}->ij', self.A, X) - self.b\n",
    "        return Y.square().sum()\n",
    "    \n",
    "    \n",
    "class LogRegression(Objective):\n",
    "    def __call__(self, X):\n",
    "        s = '' if X.ndim < 2 else 'i'\n",
    "        Y = torch.einsum(f'ij,ijk,k{s}->ij', self.b, self.A, X)\n",
    "        Y = torch.logaddexp(-Y, torch.tensor(0.)).mean()\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGM:\n",
    "    \"\"\"\n",
    "    Base class for decentralized gradient methods\n",
    "    \"\"\"\n",
    "    def __init__(self, W, F, alpha=1.):\n",
    "        self.W = W\n",
    "        self.F = F\n",
    "        self.n = W.size(0)\n",
    "        self.alpha = alpha\n",
    "        self._initLogs()\n",
    "        \n",
    "    def _initLogs(self):\n",
    "        self.logs = {0: [], 1: [], 2: [], 3: []}\n",
    "        \n",
    "    def _metric2(self, X):\n",
    "        h = X.new(self.n).fill_(1.)\n",
    "        Q = torch.norm(X - X/self.n @ h[:,None]*h)\n",
    "        return Q\n",
    "    \n",
    "    def _metric3(self, X):\n",
    "        ImW = (-self.W).as_strided(\n",
    "            [self.n], [self.n+1]).add(torch.ones(self.n))\n",
    "        Q = torch.norm(X @ ImW)\n",
    "        return Q\n",
    "        \n",
    "    def _record(self, X, k):\n",
    "        self.logs[1].append(self.F(X.mean(1)).item())\n",
    "        self.logs[2].append(self._metric2(X).item())\n",
    "        self.logs[3].append(self._metric3(X).item())\n",
    "        self.logs[0].append(k)\n",
    "        \n",
    "        \n",
    "class EXTRON(DGM):\n",
    "    \"\"\"\n",
    "    ONe-process EXTRA algorithm\n",
    "    \"\"\"\n",
    "    def _step1(self, X0):\n",
    "        X0.requires_grad_(True)\n",
    "        G0 = D(self.F(X0), X0)\n",
    "        with torch.no_grad():\n",
    "            X1 = X0@self.W - self.alpha*G0\n",
    "        return G0, X1\n",
    "\n",
    "    def _step2(self, X0, G0, X1):\n",
    "        X1.requires_grad_(True)\n",
    "        G1 = D(self.F(X1), X1)\n",
    "        with torch.no_grad():\n",
    "            X2 = X1 - X0/2 + (X1-X0/2)@self.W - self.alpha*(G1-G0)\n",
    "        return X1, G1, X2\n",
    "\n",
    "    def run(self, X0, G0=None, X1=None, n_iters=10, lp=1):\n",
    "        if G0 is None or X1 is None:\n",
    "            G0, X1 = self._step1(X0)\n",
    "            self._initLogs()\n",
    "            self._record(X0, 0)\n",
    "            self._record(X1, 1)\n",
    "\n",
    "        for k in range(n_iters-1):\n",
    "            X0, G0, X1 = self._step2(X0, G0, X1)\n",
    "            if k%lp == 0: self._record(X1, k)\n",
    "\n",
    "        return X0, G0, X1\n",
    "\n",
    "\n",
    "class DIGONing(DGM):\n",
    "    \"\"\"\n",
    "    ONe-process DIGing algorithm\n",
    "    \"\"\"\n",
    "    def run(self, X0, Y0=None, n_iters=10, lp=1):\n",
    "        if Y0 is None:\n",
    "            self._initLogs()\n",
    "            self._record(X0, 0)\n",
    "            X0.requires_grad_(True)\n",
    "            Y0 = D(self.F(X0), X0)\n",
    "            G0 = Y0.clone()\n",
    "            \n",
    "        for k in range(1, n_iters):\n",
    "            with torch.no_grad():\n",
    "                X1 = X0@self.W - self.alpha*Y0\n",
    "                \n",
    "            X1.requires_grad_(True)\n",
    "            G1 = D(self.F(X1), X1)\n",
    "            with torch.no_grad():\n",
    "                Y1 = Y0@self.W + G1 - G0\n",
    "                \n",
    "            X0, Y0, G0 = X1, Y1, G1\n",
    "            if k%lp == 0: self._record(X1, k)\n",
    "            \n",
    "        return X0, G0, X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = load_svmlight_file('data/a9a.2')\n",
    "A = torch.Tensor(A.todense())\n",
    "b = torch.Tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 20\n",
    "\n",
    "#G = nx.path_graph(num_nodes)\n",
    "#G = nx.cycle_graph(num_nodes)\n",
    "#G = nx.complete_graph(num_nodes)\n",
    "G = nx.erdos_renyi_graph(num_nodes, .2)\n",
    "\n",
    "S = nx.adjacency_matrix(G).todense()\n",
    "W = metropolis_weights(torch.Tensor(S))\n",
    "assert torch.allclose(W @ torch.ones(len(W)), torch.ones(len(W)))\n",
    "assert torch.allclose(torch.ones(len(W)) @ W, torch.ones(len(W)))\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = LogRegression(A, b, num_nodes)\n",
    "X0 = torch.zeros(A.size(1), num_nodes)\n",
    "opt = EXTRON(W, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.run(X0, n_iters=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(opt.logs[1]);\n",
    "plt.title('Optimization Functional Value over Iteration Number', size=20)\n",
    "plt.xlabel('# k', size=20)\n",
    "plt.ylabel('f(x)', size=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(opt.logs[2][1::]);\n",
    "plt.title(r'$||X(I-11^T)||^2$', size=20)\n",
    "plt.xlabel('# k', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
